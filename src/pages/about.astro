---
import Layout from "../layouts/Layout.astro";
import Sidebar from "../layouts/layout-1/Sidebar.astro";
---

<Layout title="about meta">
  <div class="aboutmeta">
    <div class="meta-all">
      <h1>Meta</h1>
      <p class="title-meta">Introducing Code Llama, an AI Tool for Coding</p>
      <div class="boxmeta">
        <h3>Takeaways</h3>
        <ul>
          <li>
            Code Llama is an AI model built on top of <a href="">Llama 2</a>,
            fine-tuned for generating and discussing code.
          </li>
          <li>It’s free for research and commercial use.</li>
        </ul>
      </div>
      <div class="meta-p">
        <p>
          Today, we’re releasing Code Llama, a large language model (LLM) that
          can use text prompts to generate and discuss code. Code Llama is
          state-of-the-art for publicly available LLMs on coding tasks. It has
          the potential to make workflows faster and more efficient for
          developers and lower the barrier to entry for people who are learning
          to code. Code Llama has the potential to be used as a productivity and
          educational tool to help programmers write more robust,
          well-documented software.
        </p>
        <p>
          We believe an open approach to AI is best for developing new AI tools
          that are innovative, safe and responsible, so we’re releasing Code
          Llama for both research and commercial use under the same community
          license as

          <a href="">Llama 2</a>
        </p>
        <p>
          Code Llama is a code-specialized version ofx <a href="">Llama 2</a>
           that was created by further training <a href="">Llama 2</a> on its
          code-specific datasets, sampling more data from that same dataset for
          longer. Essentially, Code Llama features enhanced coding capabilities.
          It can generate code and natural language about code, from both code
          and natural language prompts (e.g., “Write me a function that outputs
          the fibonacci sequence”). It can also be used for code completion and
          debugging. It supports many of the most popular programming languages
          used today, including Python, C++, Java, PHP, Typescript (Javascript),
          C#, Bash and more.
        </p>
        <p>
          We are releasing three sizes of Code Llama with 7B, 13B and 34B
          parameters respectively. Each of these models is trained with 500B
          tokens of code and code-related data. The 7B and 13B base and instruct
          models have also been trained with fill-in-the-middle (FIM)
          capability, allowing them to insert code into existing code, meaning
          they can support tasks like code completion right out of the box.
        </p>
        <p>
          The three models address different serving and latency requirements.
          The 7B model, for example, can be served on a single GPU. The 34B
          model returns the best results and allows for better coding
          assistance, but the smaller 7B and 13B models are faster and more
          suitable for tasks that require low latency, like real-time code
          completion.
        </p>
        <p>
          We also further fine-tuned two additional variations of Code Llama:
          Code Llama – Python and Code Llama – Instruct.
        </p>
        <p>
          Code Llama – Python is a language specialized variation of Code Llama,
          further fine-tuned on 100B tokens of Python code. Because Python is
          the most benchmarked language for code generation, and because Python
          and
          <a href="">PyTorch</a> play an important role in the AI community – we
          believe a specialized model provides additional utility.
        </p>
        <p>
          Code Llama – Instruct is an instruction fine-tuned and aligned
          variation of Code Llama. Instruction tuning continues the training
          process, but with a different objective. The model is fed a natural
          language instruction input and the expected output. This makes it
          better at understanding what people expect out of their prompts. We
          recommend using Code Llama – Instruct variants whenever using Code
          Llama for code generation since Code Llama – Instruct has been
          fine-tuned to generate helpful and safe answers in natural language.
        </p>
        <p>
          Programmers are already using LLMs to assist in a variety of tasks.
          The goal is to make developer workflows more efficient so that they
          can focus on the most human-centric aspects of their job, rather than
          repetitive tasks. We believe that AI models, and LLMs for coding in
          particular, benefit most from an open approach, both in terms of
          innovation and safety. Publicly available, code-specific models can
          facilitate the development of new technologies that improve peoples’
          lives. By releasing code models like Code Llama, the entire community
          can evaluate their capabilities, identify issues and fix
          vulnerabilities.
        </p>
        <p>
          Code Llama is designed to support software engineers in all sectors —
          including research, industry, open source projects, NGOs and
          businesses. But there are still many more use cases to support. We
          hope Code Llama will inspire others to leverage <a href="">Llama 2</a>
           to create new innovative tools for research and commercial products.
        </p>
        <p>
          Learn more about Code Llama on our <a href="">AI blog</a> or download
          the <a href="">Code</a>
          <a href="">Llama model.</a>
        </p>
      </div>
    </div>
    <div class="sidebar">
      <Sidebar />
    </div>
  </div>
</Layout>

<style>
  * {
    margin: 0;
    padding: 0;
    box-sizing: border-box;
  }
  .aboutmeta {
    display: flex;
    margin: 0px 100px;
  }
  .meta-all {
    margin-top: 20px;
    background-color: white;
    border-radius: 5px;
    padding: 20px;
    border: 1px solid #d1d1d1;
  }
  .meta-all h1 {
    border-bottom: 5px solid #2e4db2;
    display: inline-block;
    margin-bottom: 10px;
  }
  .title-meta {
    font-size: 40px;
    color: #575757;
  }
  .boxmeta {
    background-color: #d1d1d1;
    border-top: 5px solid #2e4db2;
    margin: 20px 50px;
    padding: 20px;
  }
  .boxmeta ul {
    margin: 20px 0px 0px 40px;
  }
  .meta-p p {
    margin-bottom: 20px;
  }
  .meta-p a {
    color: #55abfb;
  }
  @media screen and (min-width: 374px) and (max-width: 480px) {
    .aboutmeta {
      margin: 20px 20px;
    }
  }
  @media screen and (min-width: 480px) and (max-width: 800px) {
    .aboutmeta {
      margin: 20px 20px;
    }
  }
</style>
